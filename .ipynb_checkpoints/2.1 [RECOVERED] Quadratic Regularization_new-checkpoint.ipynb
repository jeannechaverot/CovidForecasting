{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from smoothing import *\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import seaborn as seabornInstance \n",
    "#from sklearn.model_selection import train_test_split \n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([X, y_recovered, y_deaths, y_recovered_smoothed, y_deaths_smoothed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of infected for past two weeks\n",
    "X = pd.read_csv('data.csv').iloc[:,1:-3].values\n",
    "\n",
    "#Number of recovered\n",
    "y_recovered = pd.read_csv('data.csv').iloc[:,-3].values\n",
    "\n",
    "#Number of recovered with transformation to smooth data\n",
    "y_rec_smoothed = pd.read_csv('data.csv').iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All different smoothing that I have tried:\n",
    "- simple exponential smoothing: smaller error:0.19\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ca2efce9e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_exponential_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "simple_exponential_smoothing(x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_rec_smoothed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5117a69b43a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_best_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/EPFL_local/Semester Project | Covid-19/HACKATHON/LauzHackCovid/smoothing.py\u001b[0m in \u001b[0;36mfind_best_alpha\u001b[0;34m(X, model)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpct_80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpct_80\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0my_rec_smoothed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpct_80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rec_smoothed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpct_80\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_rec_smoothed' is not defined"
     ]
    }
   ],
   "source": [
    "find_best_alpha(X, y_rec_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_alpha(X):\n",
    "    \"\"\"Returns optimal alpha such that MAPE error is minimized,along with the MAPE index error in question, and its value\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    alphas = [round(0.05*i, 2) for i in range(20)]\n",
    "    mapes = []\n",
    "    pct_80 = int(np.ceil(80*len(X)/100))\n",
    "\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for j in range(X.shape[1]):\n",
    "            X_new[:,j]= simple_exponential_smoothing(X[:,j], alpha)\n",
    "\n",
    "\n",
    "        X_train, X_test = X_new[:pct_80], X_new[pct_80:]\n",
    "        y_train, y_test =y_rec_smoothed[:pct_80], y_rec_smoothed[pct_80:]\n",
    "\n",
    "\n",
    "        index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "        P, q, G, h = generate_params(X_train, y_train, index)\n",
    "        gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "        y_pred = X_test@gamma\n",
    "\n",
    "        mapes.append(mape(y_test, y_pred))\n",
    "\n",
    "    return mapes\n",
    "\n",
    "#alphas[np.argmin(mapes)],np.argmin(mapes), min(mapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimum K for gaussian smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1962133017320911,\n",
       " 0.19139159407688044,\n",
       " 0.19228204242441613,\n",
       " 0.19551647125345128,\n",
       " 0.1990373864834645]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_K(X, y_rec_smoothed, 'even')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimum K for gaussian smoothing, odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2099757265627456,\n",
       " 0.2080108112263042,\n",
       " 0.20462954928996785,\n",
       " 0.21036154040556126,\n",
       " 0.21084827372445283]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_K(X, y_rec_smoothed, 'odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19606331350419132"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.zeros(X.shape)\n",
    "for j in range(X.shape[1]):\n",
    "    X_new[:,j]= simple_exponential_smoothing(X[:,j], 0.9596)\n",
    "\n",
    "X_train, X_test = X_new[:pct_80], X_new[pct_80:]\n",
    "y_train, y_test =y_rec_smoothed[:pct_80], y_rec_smoothed[pct_80:]\n",
    "\n",
    "\n",
    "index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "P, q, G, h = generate_params(X_train, y_train, index)\n",
    "gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "y_pred = X_test@gamma\n",
    "\n",
    "mape(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- Create matrix M\n",
    "- Create matrix X (DONE)\n",
    "- Compute X^TX\n",
    "- Compute M^TM\n",
    "- Verify M^TM value, if it coincides with the one G.O. wrote in report\n",
    "- install library, define instances, run optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_90 = int(np.ceil(90*len(X)/100))\n",
    "pct_80 = int(np.ceil(80*len(X)/100))\n",
    "pct_70 = int(np.ceil(70*len(X)/100))\n",
    "\n",
    "X_train, X_test = X[:pct_80], X[pct_80:]\n",
    "y_train, y_test =y_rec_smoothed[:pct_80], y_rec_smoothed[pct_80:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "\n",
    "def create_M(N):\n",
    "    M = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i==0:\n",
    "                if j == 0:\n",
    "                    M[i,j]=1\n",
    "                else:\n",
    "                    M[i,j]=0\n",
    "            elif (i==j):\n",
    "                M[i,j]=1\n",
    "            elif (j == (i-1)):\n",
    "                M[i,j] = -1\n",
    "            else:\n",
    "                M[i,j]=0\n",
    "    return M\n",
    "\n",
    "def generate_G(index):\n",
    "    \"\"\"index: represents k^*, gamma_{k^*} is such that gamma_0 <= gamma_1 <= ...<= gamma_{k^*} >= ... >= gamma_N\n",
    "    This function generates a matrix G such that either gamma_index or gamma_{index+1} is the maximum\n",
    "    \"\"\" \n",
    "    #this constraint verifies the gaussian-like distribution of the gamma\n",
    "    G = np.zeros((N,N))\n",
    "    for i in range(0, index):\n",
    "        for j in range(N):\n",
    "            if (i==j):\n",
    "                G[i,j] = 1\n",
    "            elif (j == i+1):\n",
    "                G[i,j] = -1\n",
    "                \n",
    "    for i in range(index, N):\n",
    "        for j in range(N):\n",
    "            if (i==j):\n",
    "                G[i,j] = -1\n",
    "            elif (j == i+1):\n",
    "                G[i,j] = 1\n",
    "    \n",
    "    # we do not put any condition on idx_th element, and use this line to verify that all gammas are superior or\n",
    "    # equal to zero\n",
    "    #G[index,:] = 0\n",
    "    #G[index, 0] = -1\n",
    "\n",
    "    \n",
    "    #this constraint verifies that -gamma_i <= 0 <=> gamma_i >= 0 forall i\n",
    "   # for i in range(N, 2*N):\n",
    "    #    for j in range(N):\n",
    "     #       if (i==N+j):\n",
    "      #          G[i,j]=-1\n",
    "    return G\n",
    "\n",
    "def generate_params(X_train, y_train,k,lambda_=1.0):\n",
    "    M = create_M(N)\n",
    "    M_tilde = M.T @ M\n",
    "    X_tilde = X_train.T @ X_train\n",
    "    P = X_tilde + lambda_*(M_tilde)\n",
    "    q = -X_train.T@y_train\n",
    "    G = generate_G(k)\n",
    "    h = np.zeros((N,1))\n",
    "    for i in range(len(h)):\n",
    "        h[i] = -0.0000001\n",
    "    return P, q, G, h\n",
    "\n",
    "def find_best_k(X_train, y_train, X_test, y_test, loss):\n",
    "    \"\"\"Returns index of maximum gamma that minimizes the mae loss\"\"\"\n",
    "    loss = {}\n",
    "    for k in range(N):\n",
    "        P, q, G, h = generate_params(X_train, y_train, k)\n",
    "        gammas = cvxopt_solve_qp(P,q, G, h)\n",
    "        y_pred = X_test@gammas\n",
    "        loss[k] = mape(y_test,y_pred)\n",
    "    return min(loss, key=loss.get)\n",
    "\n",
    "\n",
    "def cvxopt_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    P = .5 * (P + P.T)  # make sure P is symmetric\n",
    "    args = [cvxopt.matrix(P), cvxopt.matrix(q)]\n",
    "    if G is not None:\n",
    "        args.extend([cvxopt.matrix(G), cvxopt.matrix(h)])\n",
    "        if A is not None:\n",
    "            args.extend([cvxopt.matrix(A), cvxopt.matrix(b)])\n",
    "    sol = cvxopt.solvers.qp(*args)\n",
    "    if 'optimal' not in sol['status']:\n",
    "        return None\n",
    "    \n",
    "    return np.array(sol['x']).reshape((P.shape[1],))\n",
    "\n",
    "# ----------------------------#\n",
    "#        LOSS FUNCTIONS \n",
    "# ----------------------------#\n",
    "\n",
    "def mape(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_test)/y_test))\n",
    "\n",
    "def mspe(y_test, y_pred):\n",
    "    return np.mean(np.square((y_pred-y_test)/y_test))\n",
    "\n",
    "# ----------------------------#\n",
    "#        SMOOTHING\n",
    "# ----------------------------#\n",
    "\n",
    "def simple_exponential_smoothing(x, alpha):\n",
    "    result = [x[0]] # first value is same as series\n",
    "    for n in range(1, len(x)):\n",
    "        result.append(alpha * x[n] + (1 - alpha) * x[n-1])\n",
    "    return result\n",
    "\n",
    "def exponential_smoothing(x, rho, K):\n",
    "    const = (1-rho)/(1-rho**(K+1))\n",
    "    new_x = []\n",
    "    \n",
    "    # range of x\n",
    "    r_x = np.arange(K, len(x)-K)\n",
    "\n",
    "    # range of k\n",
    "    r_k = np.arange(0,K)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if i not in r_x:\n",
    "            new_x.append(x[i])\n",
    "        else:\n",
    "            ls = []\n",
    "            for k in r_k:\n",
    "                print('rho: ', rho, 'k: ', k, 'x[i-k]: ', x[i-k])\n",
    "                ls.append(int(const*rho**k*x[i-k]))\n",
    "            new_x.append(np.sum(ls))\n",
    "                \n",
    "    return new_x\n",
    "\n",
    "def find_best_alpha(X):\n",
    "    \"\"\"Returns optimal alpha such that MAPE error is minimized,along with the MAPE index error in question, and its value\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    alphas = np.linspace(0,1,100)\n",
    "    mapes = []\n",
    "    pct_80 = int(np.ceil(80*len(X)/100))\n",
    "\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for j in range(X.shape[1]):\n",
    "            X_new[:,j]= exponential_smoothing(X[:,j], alpha)\n",
    "\n",
    "\n",
    "        X_train, X_test = X_new[:pct_80], X_new[pct_80:]\n",
    "        y_train, y_test =y_rec_smoothed[:pct_80], y_rec_smoothed[pct_80:]\n",
    "\n",
    "\n",
    "        index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "        P, q, G, h = generate_params(X_train, y_train, index)\n",
    "        gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "        y_pred = X_test@gamma\n",
    "\n",
    "        mapes.append(mape(y_test, y_pred))\n",
    "\n",
    "    return alphas[np.argmin(mapes)],np.argmin(mapes), min(mapes)\n",
    "\n",
    "\n",
    "# ----------------------------#\n",
    "#        GENERATE PREDICTIONS \n",
    "# ----------------------------#\n",
    "\n",
    "index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "P, q, G, h = generate_params(X_train, y_train, index)\n",
    "gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "y_pred = X_test@gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.93687219e-02, 3.95964166e-04, 3.95472915e-04, 3.94651444e-04,\n",
       "       1.72234221e-06, 1.13527207e-06, 9.09358938e-07, 7.86664943e-07,\n",
       "       6.79212987e-07, 5.77596190e-07, 4.79386781e-07, 3.83157042e-07,\n",
       "       2.87740749e-07, 1.93003503e-07, 9.88426562e-08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a14dbd860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'gammas': gamma}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400.0</td>\n",
       "      <td>416.631812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400.0</td>\n",
       "      <td>385.564926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>369.565330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>363.606562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>342.839025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700.0</td>\n",
       "      <td>321.662534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200.0</td>\n",
       "      <td>301.518144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300.0</td>\n",
       "      <td>308.588782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200.0</td>\n",
       "      <td>270.250344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200.0</td>\n",
       "      <td>246.282775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300.0</td>\n",
       "      <td>234.282178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200.0</td>\n",
       "      <td>221.205929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200.0</td>\n",
       "      <td>182.532758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150.0</td>\n",
       "      <td>171.248871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150.0</td>\n",
       "      <td>155.458658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual   Predicted\n",
       "0    400.0  416.631812\n",
       "1    400.0  385.564926\n",
       "2    500.0  369.565330\n",
       "3    300.0  363.606562\n",
       "4    300.0  342.839025\n",
       "5    700.0  321.662534\n",
       "6    200.0  301.518144\n",
       "7    300.0  308.588782\n",
       "8    200.0  270.250344\n",
       "9    200.0  246.282775\n",
       "10   300.0  234.282178\n",
       "11   200.0  221.205929\n",
       "12   200.0  182.532758\n",
       "13   150.0  171.248871\n",
       "14   150.0  155.458658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 66.93487840414923\n",
      "Mean Squared Error: 12635.350196162122\n",
      "Root Mean Squared Error: 112.40707360376447\n",
      "Mean Absolute percentage error: 0.1962132211473953\n",
      "Mean Square percentage error: 0.06347971629998996\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Mean Absolute percentage error:', mape(y_test, y_pred))  \n",
    "print('Mean Square percentage error:', mspe(y_test, y_pred))  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run same but delete columns 6: and then delete columns 4: (see diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = X[:,:4]\n",
    "X_6 = X[:,:6]\n",
    "N = X_4.shape[1]\n",
    "pct_90 = int(np.ceil(90*len(X_4)/100))\n",
    "pct_80 = int(np.ceil(80*len(X_4)/100))\n",
    "pct_70 = int(np.ceil(70*len(X_4)/100))\n",
    "\n",
    "X_train, X_test = X_4[:pct_80], X_4[pct_80:]\n",
    "y_train, y_test =y_rec_smoothed[:pct_80], y_rec_smoothed[pct_80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "P, q, G, h = generate_params(X_train, y_train, index)\n",
    "gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "y_pred = X_test@gamma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_4\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Mean Absolute percentage error:', mape(y_test, y_pred))  \n",
    "print('Mean Square percentage error:', mspe(y_test, y_pred))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four independent splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the model with **4 gammas** to perform cross validation in order to find the best parameters. As we have around 70 data points, and need at least twice the number of gammas as number of training points, we start with 10 data points. We estimate 10 data points for training, and three for validation. As we have $\\frac{69}{13}= 5.3$, we will do five folds. Each fold has 14 points, except for last fold with 13. We validate on two last data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we split every 13 data points, this is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_X = np.array_split(X_4, 4, axis=0)\n",
    "splits_y = np.array_split(y_rec_smoothed, 4, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(splits_X, splits_y,lambda_=1.0):  \n",
    "    y_vals = []\n",
    "    y_preds = []\n",
    "    mapes = []\n",
    "    maes = []\n",
    "\n",
    "    for X, y in zip(splits_X, splits_y):\n",
    "        pct_90 = int(np.floor(90*len(X)/100))\n",
    "\n",
    "        X_train = X[:pct_90]\n",
    "        X_val = X[pct_90:]\n",
    "        y_train = y[:pct_90]\n",
    "        y_val = y[pct_90:]\n",
    "        index = find_best_k(X_train, y_train, X_val, y_val, 'mape')\n",
    "        P, q, G, h = generate_params(X_train, y_train, index,lambda_)\n",
    "        gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "        y_pred = X_val@gamma\n",
    "\n",
    "        y_vals.append(y_val)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "        mapes.append(mape(y_val, y_pred))\n",
    "        maes.append(metrics.mean_absolute_error(y_val, y_pred))\n",
    "        \n",
    "    y_vals = [item for sublist in y_vals for item in sublist]\n",
    "    y_preds =[item for sublist in y_preds for item in sublist]\n",
    "        \n",
    "    return mapes, maes, y_vals, y_preds\n",
    "\n",
    "mapes, maes, y_vals, y_preds = cross_val(splits_X, splits_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_vals, 'Predicted': y_preds})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advancement validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want our train set to be of size 40, and then we shift of 10 data points at each new iteration.\n",
    "# the size of our test set is the rest of the dataset points\n",
    "splits = int(np.floor((X_4.shape[0] - 40)/10))\n",
    "\n",
    "##\n",
    "\n",
    "mapes = []\n",
    "maes = []\n",
    "y_vals = []\n",
    "y_preds = []\n",
    "\n",
    "for i in range(splits):\n",
    "\n",
    "    begin = 10*i\n",
    "    end = 40 + 10*i\n",
    "    \n",
    "    X_tr = X_4[begin:end,:]\n",
    "    y_tr = y_rec_smoothed[begin:end]\n",
    "    \n",
    "    X_te = X_4[end:,:]\n",
    "    y_te = y_rec_smoothed[end:]\n",
    "    \n",
    "    # Run the model\n",
    "    \n",
    "    index = find_best_k(X_tr, y_tr, X_te, y_te, 'mape')\n",
    "    P, q, G, h = generate_params(X_tr, y_tr, index,10e-5)\n",
    "    gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "    y_pred = X_te@gamma\n",
    "\n",
    "    y_vals.append(y_te)\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "    mapes.append(mape(y_te, y_pred))\n",
    "    maes.append(metrics.mean_absolute_error(y_te, y_pred))\n",
    "        \n",
    "y_vals = [item for sublist in y_vals for item in sublist]\n",
    "y_preds =[item for sublist in y_preds for item in sublist]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for each split we have the following MAPE losses: {}, \\nResulting in a mean MAPE of {}'.format(mapes, np.mean(mapes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best hyperparameter $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function we want to minimize\n",
    "# we want to minimize the mean loss function MAE from our cross validation run\n",
    "def f(lambda_):\n",
    "    mapes, maes, y_vals, y_preds = cross_val(splits_X, splits_y, lambda_)\n",
    "    return np.mean(maes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(f,1.0,method='SLSQP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "space  = [Real(10**-5, 10**0, name='learning_rate')]\n",
    "\n",
    "res = gp_minimize(f,space)\n",
    "lambda_ = res['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_per_lambda():\n",
    "    lambdas = [-10,-1,0, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1, 1, 10]\n",
    "    mapes = []\n",
    "    for l in lambdas:\n",
    "        X_train = X_4[:pct_80]\n",
    "        X_test = X_4[pct_80:]\n",
    "        y_train = y_recovered[:pct_80]\n",
    "        y_test = y_recovered[pct_80:]\n",
    "        #print(X_test@gamma)\n",
    "        #print(y_test)\n",
    "        index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "        P, q, G, h = generate_params(X_train, y_train, index,l)\n",
    "        gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "        y_pred = X_test@gamma\n",
    "        mapes.append(format(100*mape(y_test, y_pred),'.20'))\n",
    "    print(mapes)\n",
    "    print(len(mapes) == len(np.unique(mapes)))\n",
    "    lambdas1 = ['-10','-1','0','10e-5', '10e-4', '10e-3', '10e-2', '10e-1', '1', '10']\n",
    "    plt.plot(lambdas1, mapes, 'b')\n",
    "        #plt.xlabel('Day')\n",
    "        #plt.ylabel('Number of Daily Recovered')\n",
    "        #plt.legend(['Predicted value','True value'])\n",
    "        #plt.title('Baseline Prediction model for k=' + str(k))\n",
    "        #plt.axvline(x=pct_80-1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_per_lambda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gammas_per_lambda():\n",
    "    lambdas = [-10, -1, 0, 10e-5, 10e-4, 10e-3, 10e-2, 10e-1, 1, 10]\n",
    "    gammas = []\n",
    "    for l in lambdas:\n",
    "        X_train = X_4[:pct_80]\n",
    "        X_test = X_4[pct_80:]\n",
    "        y_train = y_recovered[:pct_80]\n",
    "        y_test = y_recovered[pct_80:]\n",
    "        #print(X_test@gamma)\n",
    "        #print(y_test)\n",
    "        index = find_best_k(X_train, y_train, X_test, y_test, 'mape')\n",
    "        P, q, G, h = generate_params(X_train, y_train, index,l)\n",
    "        gamma = cvxopt_solve_qp(P, q, G, h)\n",
    "        y_pred = X_test@gamma\n",
    "        gammas.append(format(np.mean(gamma), '.20f'))\n",
    "    print(gammas)\n",
    "    lambdas1 = ['-10','-1','0','10e-5', '10e-4', '10e-3', '10e-2', '10e-1', '1', '10']\n",
    "\n",
    "    plt.plot(lambdas1, gammas, 'b')\n",
    "        #plt.xlabel('Day')\n",
    "        #plt.ylabel('Number of Daily Recovered')\n",
    "        #plt.legend(['Predicted value','True value'])\n",
    "        #plt.title('Baseline Prediction model for k=' + str(k))\n",
    "        #plt.axvline(x=pct_80-1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gammas_per_lambda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
